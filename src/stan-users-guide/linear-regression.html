<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.1 Linear regression | regression.knit</title>
  <meta name="description" content="" />
  <meta name="generator" content="bookdown 0.34 and GitBook 2.6.7" />

  <meta property="og:title" content="1.1 Linear regression | regression.knit" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.1 Linear regression | regression.knit" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="regression-models.html"/>
<link rel="next" href="QR-reparameterization.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="stan-manual.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li style="font-size:110%; font-weight:400; font-family: Verdana, Helvetica, sans; line-height:1.4; margin: 0.5em 0 0 1em"><a href="https://mc-stan.org/docs/stan-users-guide/index.html" style="color:#4183C4">Stan User's Guide</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="regression-models.html"><a href="regression-models.html"><i class="fa fa-check"></i><b>1</b> Regression Models</a>
<ul>
<li class="chapter" data-level="1.1" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>1.1</b> Linear regression</a>
<ul>
<li class="chapter" data-level="" data-path="linear-regression.html"><a href="linear-regression.html#vectorization.section"><i class="fa fa-check"></i>Matrix notation and vectorization</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="QR-reparameterization.html"><a href="QR-reparameterization.html"><i class="fa fa-check"></i><b>1.2</b> The QR reparameterization</a></li>
<li class="chapter" data-level="1.3" data-path="regression-priors.html"><a href="regression-priors.html"><i class="fa fa-check"></i><b>1.3</b> Priors for coefficients and scales</a></li>
<li class="chapter" data-level="1.4" data-path="robust-noise-models.html"><a href="robust-noise-models.html"><i class="fa fa-check"></i><b>1.4</b> Robust noise models</a></li>
<li class="chapter" data-level="1.5" data-path="logistic-probit-regression.html"><a href="logistic-probit-regression.html"><i class="fa fa-check"></i><b>1.5</b> Logistic and probit regression</a></li>
<li class="chapter" data-level="1.6" data-path="multi-logit.html"><a href="multi-logit.html"><i class="fa fa-check"></i><b>1.6</b> Multi-logit regression</a>
<ul>
<li class="chapter" data-level="" data-path="multi-logit.html"><a href="multi-logit.html#identifiability"><i class="fa fa-check"></i>Identifiability</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="parameterizing-centered-vectors.html"><a href="parameterizing-centered-vectors.html"><i class="fa fa-check"></i><b>1.7</b> Parameterizing centered vectors</a>
<ul>
<li class="chapter" data-level="" data-path="parameterizing-centered-vectors.html"><a href="parameterizing-centered-vectors.html#k-1-degrees-of-freedom"><i class="fa fa-check"></i><span class="math inline">\(K-1\)</span> degrees of freedom</a></li>
<li class="chapter" data-level="" data-path="parameterizing-centered-vectors.html"><a href="parameterizing-centered-vectors.html#qr-decomposition"><i class="fa fa-check"></i>QR decomposition</a></li>
<li class="chapter" data-level="" data-path="parameterizing-centered-vectors.html"><a href="parameterizing-centered-vectors.html#translated-and-scaled-simplex"><i class="fa fa-check"></i>Translated and scaled simplex</a></li>
<li class="chapter" data-level="" data-path="parameterizing-centered-vectors.html"><a href="parameterizing-centered-vectors.html#soft-centering"><i class="fa fa-check"></i>Soft centering</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="ordered-logistic.html"><a href="ordered-logistic.html"><i class="fa fa-check"></i><b>1.8</b> Ordered logistic and probit regression</a>
<ul>
<li class="chapter" data-level="" data-path="ordered-logistic.html"><a href="ordered-logistic.html#ordered-logistic-regression"><i class="fa fa-check"></i>Ordered logistic regression</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="hierarchical-logistic-regression.html"><a href="hierarchical-logistic-regression.html"><i class="fa fa-check"></i><b>1.9</b> Hierarchical logistic regression</a></li>
<li class="chapter" data-level="1.10" data-path="hierarchical-priors.html"><a href="hierarchical-priors.html"><i class="fa fa-check"></i><b>1.10</b> Hierarchical priors</a>
<ul>
<li class="chapter" data-level="" data-path="hierarchical-priors.html"><a href="hierarchical-priors.html#boundary-avoiding-priors-for-mle-in-hierarchical-models"><i class="fa fa-check"></i>Boundary-avoiding priors for MLE in hierarchical models</a></li>
</ul></li>
<li class="chapter" data-level="1.11" data-path="item-response-models.html"><a href="item-response-models.html"><i class="fa fa-check"></i><b>1.11</b> Item-response theory models</a>
<ul>
<li class="chapter" data-level="" data-path="item-response-models.html"><a href="item-response-models.html#data-declaration-with-missingness"><i class="fa fa-check"></i>Data declaration with missingness</a></li>
<li class="chapter" data-level="" data-path="item-response-models.html"><a href="item-response-models.html#pl-rasch-model"><i class="fa fa-check"></i>1PL (Rasch) model</a></li>
<li class="chapter" data-level="" data-path="item-response-models.html"><a href="item-response-models.html#multilevel-2pl-model"><i class="fa fa-check"></i>Multilevel 2PL model</a></li>
</ul></li>
<li class="chapter" data-level="1.12" data-path="priors-for-identification.html"><a href="priors-for-identification.html"><i class="fa fa-check"></i><b>1.12</b> Priors for identifiability</a>
<ul>
<li class="chapter" data-level="" data-path="priors-for-identification.html"><a href="priors-for-identification.html#location-and-scale-invariance"><i class="fa fa-check"></i>Location and scale invariance</a></li>
<li class="chapter" data-level="" data-path="priors-for-identification.html"><a href="priors-for-identification.html#collinearity"><i class="fa fa-check"></i>Collinearity</a></li>
<li class="chapter" data-level="" data-path="priors-for-identification.html"><a href="priors-for-identification.html#separability"><i class="fa fa-check"></i>Separability</a></li>
</ul></li>
<li class="chapter" data-level="1.13" data-path="multivariate-hierarchical-priors.html"><a href="multivariate-hierarchical-priors.html"><i class="fa fa-check"></i><b>1.13</b> Multivariate priors for hierarchical models</a>
<ul>
<li class="chapter" data-level="" data-path="multivariate-hierarchical-priors.html"><a href="multivariate-hierarchical-priors.html#multivariate-regression-example"><i class="fa fa-check"></i>Multivariate regression example</a></li>
</ul></li>
<li class="chapter" data-level="1.14" data-path="prediction-forecasting-and-backcasting.html"><a href="prediction-forecasting-and-backcasting.html"><i class="fa fa-check"></i><b>1.14</b> Prediction, forecasting, and backcasting</a>
<ul>
<li class="chapter" data-level="" data-path="prediction-forecasting-and-backcasting.html"><a href="prediction-forecasting-and-backcasting.html#programming-predictions"><i class="fa fa-check"></i>Programming predictions</a></li>
<li class="chapter" data-level="" data-path="prediction-forecasting-and-backcasting.html"><a href="prediction-forecasting-and-backcasting.html#predictions-as-generated-quantities"><i class="fa fa-check"></i>Predictions as generated quantities</a></li>
</ul></li>
<li class="chapter" data-level="1.15" data-path="multivariate-outcomes.html"><a href="multivariate-outcomes.html"><i class="fa fa-check"></i><b>1.15</b> Multivariate outcomes</a>
<ul>
<li class="chapter" data-level="" data-path="multivariate-outcomes.html"><a href="multivariate-outcomes.html#seemingly-unrelated-regressions"><i class="fa fa-check"></i>Seemingly unrelated regressions</a></li>
<li class="chapter" data-level="" data-path="multivariate-outcomes.html"><a href="multivariate-outcomes.html#multivariate-probit-regression"><i class="fa fa-check"></i>Multivariate probit regression</a></li>
</ul></li>
<li class="chapter" data-level="1.16" data-path="applications-of-pseudorandom-number-generation.html"><a href="applications-of-pseudorandom-number-generation.html"><i class="fa fa-check"></i><b>1.16</b> Applications of pseudorandom number generation</a>
<ul>
<li class="chapter" data-level="" data-path="applications-of-pseudorandom-number-generation.html"><a href="applications-of-pseudorandom-number-generation.html#prediction"><i class="fa fa-check"></i>Prediction</a></li>
<li class="chapter" data-level="" data-path="applications-of-pseudorandom-number-generation.html"><a href="applications-of-pseudorandom-number-generation.html#posterior-predictive-checks"><i class="fa fa-check"></i>Posterior predictive checks</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="linear-regression" class="section level2 hasAnchor" number="1.1">
<h2><span class="header-section-number">1.1</span> Linear regression<a href="linear-regression.html#linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The simplest linear regression model is the following, with a single
predictor and a slope and intercept coefficient, and normally
distributed noise. This model can be written using standard
regression notation as
<span class="math display">\[
y_n = \alpha + \beta x_n + \epsilon_n
\quad\text{where}\quad
\epsilon_n \sim \operatorname{normal}(0,\sigma).
\]</span></p>
<p>This is equivalent to the following sampling involving the
residual,
<span class="math display">\[
y_n - (\alpha + \beta X_n) \sim \operatorname{normal}(0,\sigma),
\]</span>
and reducing still further, to
<span class="math display">\[
y_n \sim \operatorname{normal}(\alpha + \beta X_n, \, \sigma).
\]</span></p>
<p>This latter form of the model is coded in Stan as follows.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode stan"><code class="sourceCode stan"><span id="cb1-1"><a href="linear-regression.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb1-2"><a href="linear-regression.html#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N;</span>
<span id="cb1-3"><a href="linear-regression.html#cb1-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N] x;</span>
<span id="cb1-4"><a href="linear-regression.html#cb1-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">vector</span>[N] y;</span>
<span id="cb1-5"><a href="linear-regression.html#cb1-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-6"><a href="linear-regression.html#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb1-7"><a href="linear-regression.html#cb1-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> alpha;</span>
<span id="cb1-8"><a href="linear-regression.html#cb1-8" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> beta;</span>
<span id="cb1-9"><a href="linear-regression.html#cb1-9" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; sigma;</span>
<span id="cb1-10"><a href="linear-regression.html#cb1-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-11"><a href="linear-regression.html#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb1-12"><a href="linear-regression.html#cb1-12" aria-hidden="true" tabindex="-1"></a>  y ~ normal(alpha + beta * x, sigma);</span>
<span id="cb1-13"><a href="linear-regression.html#cb1-13" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>There are <code>N</code> observations and for each observation, <span class="math inline">\(n \in N\)</span>, we have predictor
<code>x[n]</code> and outcome <code>y[n]</code>. The intercept and slope parameters are
<code>alpha</code> and <code>beta</code>. The model assumes a normally
distributed noise term with scale <code>sigma</code>. This model has
improper priors for the two regression coefficients.</p>
<div id="vectorization.section" class="section level3 unnumbered hasAnchor">
<h3>Matrix notation and vectorization<a href="linear-regression.html#vectorization.section" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The sampling statement in the previous model is vectorized, with</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode stan"><code class="sourceCode stan"><span id="cb2-1"><a href="linear-regression.html#cb2-1" aria-hidden="true" tabindex="-1"></a>y ~ normal(alpha + beta * x, sigma);</span></code></pre></div>
<p>providing the same model as the unvectorized version,</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode stan"><code class="sourceCode stan"><span id="cb3-1"><a href="linear-regression.html#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N) {</span>
<span id="cb3-2"><a href="linear-regression.html#cb3-2" aria-hidden="true" tabindex="-1"></a>  y[n] ~ normal(alpha + beta * x[n], sigma);</span>
<span id="cb3-3"><a href="linear-regression.html#cb3-3" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>In addition to being more concise, the vectorized form is much faster.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<p>In general, Stan allows the arguments to distributions such as
<code>normal</code> to be vectors. If any of the other arguments are vectors or
arrays, they have to be the same size. If any of the other arguments
is a scalar, it is reused for each vector entry. See <a href="linear-regression.html#vectorization.section">the
vectorization section</a> for more information on
vectorization of probability functions.</p>
<p>The other reason this works is that Stan’s arithmetic operators are
overloaded to perform matrix arithmetic on matrices. In this case,
because <code>x</code> is of type <code>vector</code> and <code>beta</code> of type
<code>real</code>, the expression <code>beta * x</code> is of type <code>vector</code>.
Because Stan supports vectorization, a regression model with more than
one predictor can be written directly using matrix notation.</p>
<pre class="stan"><code>data {
  int&lt;lower=0&gt; N;   // number of data items
  int&lt;lower=0&gt; K;   // number of predictors
  matrix[N, K] x;   // predictor matrix
  vector[N] y;      // outcome vector
}
parameters {
  real alpha;           // intercept
  vector[K] beta;       // coefficients for predictors
  real&lt;lower=0&gt; sigma;  // error scale
}
model {
  y ~ normal(x * beta + alpha, sigma);  // likelihood
}</code></pre>
<p>The constraint <code>lower=0</code> in the declaration of <code>sigma</code>
constrains the value to be greater than or equal to 0. With no prior
in the model block, the effect is an improper prior on non-negative
real numbers. Although a more informative prior may be added, improper
priors are acceptable as long as they lead to proper posteriors.</p>
<p>In the model above, <code>x</code> is an <span class="math inline">\(N \times K\)</span> matrix of predictors
and <code>beta</code> a <span class="math inline">\(K\)</span>-vector of coefficients, so <code>x * beta</code> is an
<span class="math inline">\(N\)</span>-vector of predictions, one for each of the <span class="math inline">\(N\)</span> data items. These
predictions line up with the outcomes in the <span class="math inline">\(N\)</span>-vector <code>y</code>, so
the entire model may be written using matrix arithmetic as shown. It
would be possible to include a column of ones in the data matrix <code>x</code> to
remove the <code>alpha</code> parameter.</p>
<p>The sampling statement in the model above is just a more efficient,
vector-based approach to coding the model with a loop, as in the
following statistically equivalent model.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode stan"><code class="sourceCode stan"><span id="cb5-1"><a href="linear-regression.html#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb5-2"><a href="linear-regression.html#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span>:N) {</span>
<span id="cb5-3"><a href="linear-regression.html#cb5-3" aria-hidden="true" tabindex="-1"></a>    y[n] ~ normal(x[n] * beta, sigma);</span>
<span id="cb5-4"><a href="linear-regression.html#cb5-4" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb5-5"><a href="linear-regression.html#cb5-5" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>With Stan’s matrix indexing scheme, <code>x[n]</code> picks out row <code>n</code>
of the matrix <code>x</code>; because <code>beta</code> is a column vector,
the product <code>x[n] * beta</code> is a scalar of type <code>real</code>.</p>
<div id="intercepts-as-inputs" class="section level4 unnumbered hasAnchor">
<h4>Intercepts as inputs<a href="linear-regression.html#intercepts-as-inputs" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In the model formulation</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode stan"><code class="sourceCode stan"><span id="cb6-1"><a href="linear-regression.html#cb6-1" aria-hidden="true" tabindex="-1"></a>y ~ normal(x * beta, sigma);</span></code></pre></div>
<p>there is no longer an intercept coefficient <code>alpha</code>. Instead, we
have assumed that the first column of the input matrix <code>x</code> is a
column of 1 values. This way, <code>beta[1]</code> plays the role of the
intercept. If the intercept gets a different prior than the slope
terms, then it would be clearer to break it out. It is also slightly
more efficient in its explicit form with the intercept variable
singled out because there’s one fewer multiplications; it should not
make that much of a difference to speed, though, so the choice should
be based on clarity.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Unlike in Python and R, which are interpreted, Stan is translated to C++ and compiled, so loops and assignment statements are fast. Vectorized code is faster in Stan because (a) the expression tree used to compute derivatives can be simplified, leading to fewer virtual function calls, and (b) computations that would be repeated in the looping version, such as <code>log(sigma)</code> in the above model, will be computed once and reused.<a href="linear-regression.html#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="regression-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="QR-reparameterization.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": "https://github.com/stan-dev/docs/tree/master/src/stan-users-guide/%s",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": false,
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
